{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-18T15:47:22.729517Z",
     "start_time": "2020-01-18T15:47:22.227538Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andrz\\AppData\\Local\\Temp\\ipykernel_12304\\3527984445.py:8: MatplotlibDeprecationWarning: The seaborn styles shipped by Matplotlib are deprecated since 3.6, as they no longer correspond to the styles shipped by seaborn. However, they will remain available as 'seaborn-v0_8-<style>'. Alternatively, directly use the seaborn API instead.\n",
      "  plt.style.use('seaborn-ticks')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import statsmodels.api as sm\n",
    "from sklearn import metrics, preprocessing\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-ticks')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-18T15:47:22.756114Z",
     "start_time": "2020-01-18T15:47:22.730550Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2178, 12)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>salary_perc</th>\n",
       "      <th>age</th>\n",
       "      <th>games_played_perc</th>\n",
       "      <th>games_started_perc</th>\n",
       "      <th>minutes_played</th>\n",
       "      <th>avg_minutes_played</th>\n",
       "      <th>WS48</th>\n",
       "      <th>PER</th>\n",
       "      <th>team_successes</th>\n",
       "      <th>player_successes</th>\n",
       "      <th>WS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>webbech01</td>\n",
       "      <td>0.300</td>\n",
       "      <td>27</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>3184</td>\n",
       "      <td>40.821</td>\n",
       "      <td>0.186</td>\n",
       "      <td>26.492</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>12.338000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>smithjo02</td>\n",
       "      <td>0.107</td>\n",
       "      <td>25</td>\n",
       "      <td>0.841463</td>\n",
       "      <td>0.719512</td>\n",
       "      <td>1941</td>\n",
       "      <td>28.130</td>\n",
       "      <td>0.109</td>\n",
       "      <td>14.600</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.407687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>olajuha01</td>\n",
       "      <td>0.119</td>\n",
       "      <td>38</td>\n",
       "      <td>0.707317</td>\n",
       "      <td>0.670732</td>\n",
       "      <td>1545</td>\n",
       "      <td>26.638</td>\n",
       "      <td>0.155</td>\n",
       "      <td>20.700</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.989063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>robinda01</td>\n",
       "      <td>0.224</td>\n",
       "      <td>35</td>\n",
       "      <td>0.978947</td>\n",
       "      <td>0.978947</td>\n",
       "      <td>2780</td>\n",
       "      <td>29.892</td>\n",
       "      <td>0.245</td>\n",
       "      <td>27.926</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>14.189583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mutomdi01</td>\n",
       "      <td>0.337</td>\n",
       "      <td>34</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>3572</td>\n",
       "      <td>36.449</td>\n",
       "      <td>0.150</td>\n",
       "      <td>24.959</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>11.162500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID  salary_perc  age  games_played_perc  games_started_perc  \\\n",
       "0  webbech01        0.300   27           0.866667            0.866667   \n",
       "1  smithjo02        0.107   25           0.841463            0.719512   \n",
       "2  olajuha01        0.119   38           0.707317            0.670732   \n",
       "3  robinda01        0.224   35           0.978947            0.978947   \n",
       "4  mutomdi01        0.337   34           0.933333            0.933333   \n",
       "\n",
       "   minutes_played  avg_minutes_played   WS48     PER  team_successes  \\\n",
       "0            3184              40.821  0.186  26.492               1   \n",
       "1            1941              28.130  0.109  14.600               0   \n",
       "2            1545              26.638  0.155  20.700               0   \n",
       "3            2780              29.892  0.245  27.926               2   \n",
       "4            3572              36.449  0.150  24.959               3   \n",
       "\n",
       "   player_successes         WS  \n",
       "0                 2  12.338000  \n",
       "1                 0   4.407687  \n",
       "2                 0   4.989063  \n",
       "3                 2  14.189583  \n",
       "4                 5  11.162500  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_o = pd.read_csv(\"data/model_data.csv\")\n",
    "print(df_o.shape)\n",
    "df_o.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2178"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df_o.copy()\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2175"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.dropna()\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-18T15:47:22.764455Z",
     "start_time": "2020-01-18T15:47:22.760361Z"
    }
   },
   "outputs": [],
   "source": [
    "target = \"salary_perc\"\n",
    "features = ['age', 'games_played_perc', 'games_started_perc', 'minutes_played', 'avg_minutes_played', 'WS48', 'PER', 'team_successes', 'player_successes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: False\n",
      "salary_perc: False\n",
      "age: False\n",
      "games_played_perc: False\n",
      "games_started_perc: False\n",
      "minutes_played: False\n",
      "avg_minutes_played: False\n",
      "WS48: False\n",
      "PER: False\n",
      "team_successes: False\n",
      "player_successes: False\n",
      "WS: False\n"
     ]
    }
   ],
   "source": [
    "for column in df.columns.values:\n",
    "    check_nan = df[f'{column}'].isnull().values.any()\n",
    "    print(f\"{column}: {check_nan}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df.iterrows():\n",
    "    check_nan = row.isnull().values.any()\n",
    "    if check_nan:\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=\"ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def TestRFRegress(\n",
    "    nFolds=5,\n",
    "    randomState=2020,\n",
    "    debug=False,\n",
    "    features=None,\n",
    "    target_col: str = \"target\",\n",
    "    *args,\n",
    "    **kwargs\n",
    "):\n",
    "    kf = KFold(n_splits=nFolds, shuffle=True, random_state=randomState)\n",
    "\n",
    "    testResults = []\n",
    "    trainResults = []\n",
    "    predictions = []\n",
    "    indices = []\n",
    "\n",
    "    if not features:\n",
    "        features = [col for col in df.columns if col != target_col]\n",
    "\n",
    "    for train, test in kf.split(df.index.values):\n",
    "        reg = RandomForestRegressor(\n",
    "            *args, **kwargs, random_state=randomState, n_jobs=-1\n",
    "        )\n",
    "        if debug:\n",
    "            print(reg)\n",
    "\n",
    "        reg.fit(df.iloc[train][features], df.iloc[train][target_col])\n",
    "\n",
    "        predsTrain = reg.predict(df.iloc[train][features])\n",
    "        preds = reg.predict(df.iloc[test][features])\n",
    "\n",
    "        predictions.append(preds.tolist().copy())\n",
    "        indices.append(df.iloc[test].index.tolist().copy())\n",
    "\n",
    "        trainScore = mean_absolute_error(df[target_col].iloc[train], predsTrain)\n",
    "        testScore = mean_absolute_error(df[target_col].iloc[test], preds)\n",
    "\n",
    "        trainResults.append(trainScore)\n",
    "        testResults.append(testScore)\n",
    "\n",
    "        if debug:\n",
    "            print(\"Train MAE:\", trainScore, \"Valid MAE:\", testScore)\n",
    "\n",
    "    return trainResults, testResults, predictions, indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-18T15:47:24.468663Z",
     "start_time": "2020-01-18T15:47:22.856848Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestRegressor(n_jobs=-1, random_state=2020)\n",
      "Train MAE: 0.011133816091954017 Valid MAE: 0.031471494252873565\n",
      "RandomForestRegressor(n_jobs=-1, random_state=2020)\n",
      "Train MAE: 0.011316942528735632 Valid MAE: 0.0314420459770115\n",
      "RandomForestRegressor(n_jobs=-1, random_state=2020)\n",
      "Train MAE: 0.01132791954022988 Valid MAE: 0.03065636781609195\n",
      "RandomForestRegressor(n_jobs=-1, random_state=2020)\n",
      "Train MAE: 0.011849798850574706 Valid MAE: 0.028411402298850575\n",
      "RandomForestRegressor(n_jobs=-1, random_state=2020)\n",
      "Train MAE: 0.011374252873563213 Valid MAE: 0.03133239080459771\n"
     ]
    }
   ],
   "source": [
    "trainResults, testResults, predictions, indices = TestRFRegress(debug=True, target_col=\"salary_perc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-18T15:47:50.976742Z",
     "start_time": "2020-01-18T15:47:24.469567Z"
    }
   },
   "outputs": [],
   "source": [
    "# Pętla po parametrze n_estimators\n",
    "for k in [10, 25, 50, 100, 200, 500, 1000]:\n",
    "    trainResults, testResults, predictions, indices = CVTestRFClass(n_estimators=k)\n",
    "    print(k, np.mean(trainResults), np.mean(testResults), np.mean(trainResults) - np.mean(testResults))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-18T15:48:12.611221Z",
     "start_time": "2020-01-18T15:47:50.977782Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for k in range(2,22,2):\n",
    "    trainResults, testResults, predictions, indices = CVTestRFClass(n_estimators=100, max_depth=k)\n",
    "    print(k, np.mean(trainResults), np.mean(testResults), np.mean(trainResults) - np.mean(testResults))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jak widać w przypadku tego zbioru algorytm skutecznie korzysta nawet z bardzo głębkoich drzew. Z drugiej strony, można zaobserwować jak wraz ze zwiększaniem głębokości drzew zwiększa się przetrenowanie modelu. Przyjrzyjmy się kolejnemu hiperparametrowi - liczby zmiennych w pojedynczym drzewie. O ile nie ustalimy inaczej, algorytm automatycznie ograniczy liczbę zmiennych na dane drzewo ustalać liczbę jako ```sqrt(n_features)```. Zobaczmy czy inna wartość będzie lepsza."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-18T15:48:12.613993Z",
     "start_time": "2020-01-18T15:48:12.612192Z"
    }
   },
   "outputs": [],
   "source": [
    "# lizczba zmiennych objaśniających\n",
    "print(len(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-18T15:48:28.865157Z",
     "start_time": "2020-01-18T15:48:12.614751Z"
    }
   },
   "outputs": [],
   "source": [
    "for k in range(2, len(features) + 1,2):\n",
    "    trainResults, testResults, predictions, indices = CVTestRFClass(n_estimators=100, max_depth=10,\n",
    "                                                                    max_features=k)\n",
    "    print(k, np.mean(trainResults), np.mean(testResults), np.mean(trainResults) - np.mean(testResults))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Przypadkiem okazało się, że reguła kciuka (4 zmienne) to rzeczywiście najlepsza wartość. Trzeba jednak pamiętać, że nie zawsze tak będzie! Testowanie hiperparametrów to zawsze bardzo ważny krok w przypadku zaawansowanych algorytmów machine learningu.\n",
    "\n",
    "W dwóch kolejnych pętlach sprawdzimy działanie `min_samples_split` oraz `min_samples_leaf`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-18T15:48:47.336560Z",
     "start_time": "2020-01-18T15:48:28.866043Z"
    }
   },
   "outputs": [],
   "source": [
    "for k in [2, 4, 6, 8, 10, 15, 20, 30]:\n",
    "    trainResults, testResults, predictions, indices = CVTestRFClass(n_estimators=100, max_depth=10,\n",
    "                                                                    max_features=4,\n",
    "                                                                    min_samples_split=k)\n",
    "    print(k, np.mean(testResults))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Skoro musimy mieć co najmniej 4 do splitu to po splicie możemy już przetestować wyłącznie wartości 1 i 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-18T15:48:51.957297Z",
     "start_time": "2020-01-18T15:48:47.337491Z"
    }
   },
   "outputs": [],
   "source": [
    "for k in [1, 2, 4]:\n",
    "    trainResults, testResults, predictions, indices = CVTestRFClass(n_estimators=100, max_depth=10,\n",
    "                                                                    max_features=4,\n",
    "                                                                    min_samples_split=6, min_samples_leaf=k)\n",
    "    print(k, np.mean(testResults))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wydaje się, że najlepszy wynik osięgnęliśmy przy głębokości 20, maksymalnej liczbie featerów 4, obserwacji przed splitem 4 i min w liściu po splicie 1. Dla tych parametrów (ale większej liczby drzew) zapiszmy predykcje naszego mdoelu i porównajmy z wczesniejszymi wynikami."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-18T15:48:57.320456Z",
     "start_time": "2020-01-18T15:48:51.958200Z"
    }
   },
   "outputs": [],
   "source": [
    "trainResults, testResults, predictions, indices = CVTestRFClass(n_estimators=500, max_depth=14,\n",
    "                                                                    max_features=6,\n",
    "                                                                    min_samples_split=4, min_samples_leaf=1)\n",
    "print(k, np.mean(testResults))\n",
    "\n",
    "modelRF = {\n",
    "    \"name\":\"RF\",\n",
    "    \"description\":\"Model RF, ze zmiennymi kategorycznymi z LE\",\n",
    "    \"specification\":'n_estimators=500, max_depth=20, max_features=4, min_samples_split=4, min_samples_leaf=1',\n",
    "    \"trainResults\":trainResults.copy(),\n",
    "    \"testResults\":testResults.copy(),\n",
    "    \"predictions\":predictions.copy(),\n",
    "    \"indices\":indices.copy(),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-18T15:48:57.325241Z",
     "start_time": "2020-01-18T15:48:57.322482Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Otwieramy plik do zapisu binarnego z wykorzystenim with\n",
    "with open(\"model_RF_1.p\", \"wb\") as fp:\n",
    "    # Zapisujemy obiekt do wskaźnika pliku\n",
    "    pickle.dump(modelRF, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-18T15:48:57.338719Z",
     "start_time": "2020-01-18T15:48:57.326384Z"
    }
   },
   "outputs": [],
   "source": [
    "# Wczytajmy też wcześniej zapisane modele\n",
    "with open(\"model_ekonometria_1.p\", \"rb\") as fp:\n",
    "    modelEkonometria = pickle.load(fp)\n",
    "    \n",
    "with open(\"model_svm_1.p\", \"rb\") as fp:\n",
    "    modelSVM = pickle.load(fp)\n",
    "    \n",
    "with open(\"model_kNN_1.p\", \"rb\") as fp:\n",
    "    modelkNN = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Porównanie wyników ze wcześniejszymi modelami\n",
    "Niektórzy już pewnie zauważyli, że wielokrotne kopiowanie kodu funkcji (np tej do rysowania krzywej ROC) pomiędzy notatnikami jest niepraktyczne i kłóci się z zasadą DRY (Don't Repeat Yourself). Zobaczmy teraz jak łatwe jest importowanie w Pythonie bibliotek i funkcji tak żeby korzystać z nich wielokrotnie.\n",
    "\n",
    "Spójrzmy na zawartośc pliku helpers.py w naszym głównym katalogu. Skopiowaliśmy tam po prostu zawartośc naszej funkcji. Dzięki temu wystarczy w tym notatniku umieścić poniższą linię, aby funkcja była już dla nas dostępna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-18T15:48:57.342172Z",
     "start_time": "2020-01-18T15:48:57.339979Z"
    }
   },
   "outputs": [],
   "source": [
    "from helpers import plotROCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-18T15:48:57.524882Z",
     "start_time": "2020-01-18T15:48:57.343061Z"
    }
   },
   "outputs": [],
   "source": [
    "res2plot = []\n",
    "true = (df[target]==\"yes\").astype(int).sort_index()\n",
    "for result in [modelRF, modelkNN, modelEkonometria, modelSVM]:\n",
    "    # Tworzymy wektor predykcji tworząc serię pandasa, a następnie sortujemy indeks\n",
    "    pred = pd.Series(sum(result[\"predictions\"], []), index=sum(result[\"indices\"], [])).sort_index()\n",
    "    res2plot.append((true, pred, result[\"name\"]))\n",
    "    \n",
    "# Wywołujemy funkcję do rysowania\n",
    "plotROCs(res2plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jak widać, dzięki lasowi losowemu uzyskano najlepszy jak dotąd wynik. Z pozostałych parametrów klasyfikatora `RandomForest` warto omówić jeszcze następujące argumenty:\n",
    "* `bootstrap` - domyślnie True, jeżeli wybrane zostanie False, wyłączymy bagging, a każde drzewo będzie budowane na pełnym zbiorze danych\n",
    "* `min_weight_fraction_leaf` - float, który określa jak mała może być część w liściu po splicie (od 0 do 1)\n",
    "* `min_impurity_decrease` - wartość float między 0 a 1, która mówi jak bardzo musi się poprawić klasyfikacja po splicie aby można było dokonać splitu."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Szukanie optymalnych wartości hiperparametrów\n",
    "Random forest jest pierwszy algorytmem, gdzie liczba hiperparametrów robi się na tyle zauważalna, że warto coś więcej powiedzieć o szukaniu hiperparametrów. Dwie najczęściej stosowane metody to *grid search* oraz *random search*. W pierwszym przypadku ustalamy sztywną siatkę wartości dla wszystkich analizowanych zmiennych, a w drugim, dla każdej zmiennej losujemy wartości.\n",
    "\n",
    "Istnieje wiele bibliotek, które specjalizują się w szukaniu hiperparametrów. Zanim po nie sięgniemy warto by jednak było najpierw zobaczyć jak prosta jest samodzielna implementacja random search i jakie daje efekty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-18T13:57:51.974562Z",
     "start_time": "2020-01-18T13:57:51.972959Z"
    }
   },
   "outputs": [],
   "source": [
    "# Przygotujmy listę do zapisywnia wyników\n",
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-18T13:59:47.702926Z",
     "start_time": "2020-01-18T13:57:52.194517Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "# Teraz napiszmy pętle, w której będziemy iterować kolejne wyszukiwania.\n",
    "for k in range(50):\n",
    "    # Przygotujmy słownik parametrów\n",
    "    # Jako punkt odniesienia do wybranych przedziałów posłużą nam wcześniejsze wyniki\n",
    "    params = {\n",
    "        \"max_depth\" : random.randint(6, 22),\n",
    "        \"max_features\" : random.randint(2, 12),\n",
    "        \"min_samples_split\" : random.randint(2, 9),\n",
    "    }\n",
    "    # Wartość min_samples_leaf musi być mniejsza niż min_samples_split\n",
    "    params[\"min_samples_leaf\"] = random.randint(1, params[\"min_samples_split\"])\n",
    "    \n",
    "    # Estymacja modelu dla wylosowanych hiperparametrów\n",
    "    trainResults, testResults, predictions, indices = CVTestRFClass(n_estimators=100,\n",
    "                                                                    max_depth=params[\"max_depth\"],\n",
    "                                                                    max_features=params[\"max_features\"],\n",
    "                                                                    min_samples_split=params[\"min_samples_split\"],\n",
    "                                                                    min_samples_leaf=params[\"min_samples_leaf\"])\n",
    "    \n",
    "    # Zapiszmy wynik\n",
    "    results.append((np.mean(testResults), params.copy()))\n",
    "    \n",
    "    # Wyświetlmy wynik bieżącej iteracji\n",
    "    print(params, np.mean(testResults))\n",
    "    \n",
    "    # Co 10 iteracji wyświetlmy sobie nasze dotychczasowe top 5\n",
    "    if k>1 and k%10==0:    \n",
    "        print(\"\\n Top 5:\")\n",
    "        for score, params in sorted(results, key=lambda x: x[0], reverse=True)[0:5]:\n",
    "            print(params, score)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-18T14:00:08.273806Z",
     "start_time": "2020-01-18T14:00:08.194801Z"
    }
   },
   "outputs": [],
   "source": [
    "# Zobaczmy jak wyglądają wyniki od najlepszego graficznie\n",
    "plt.plot([x for x, y in sorted(results, key=lambda x: x[0], reverse=True)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jak widać zdecydowana większość (60-80%) jest na relatywnie wysokim poziomie, a tylko około 20% to kiepskie wyniki. Co więcej medianowy wynik nie różni się bardzo mocno od najlepszego z wyników."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-18T14:01:48.149403Z",
     "start_time": "2020-01-18T14:01:48.146338Z"
    }
   },
   "outputs": [],
   "source": [
    "# Możemy tez zobaczyć jak z czasem poprawiał się najlepszy wynik:\n",
    "bestHistory = []\n",
    "for k in range(1,len(results)):\n",
    "    # List comprehension: dla k pierwszych wartości zwróć maximum\n",
    "    bestHistory.append(np.max([x for x, y in sorted(results[:k], key=lambda x: x[0], reverse=True)]))\n",
    "# Wykres historii\n",
    "plt.plot(bestHistory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Powyższy wykres wyraźnie pokazuje, że już po 15 iteracjach *random search* znaleźliśmy hiperparametry, który były bardzo blisko optymalnej kombinacji znalezionej w procedurze."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5. Feature importance\n",
    "W zależności od algorytmu, że obiekt zwracany przez funkcję estymującą model, ma wbudowane metody, które pomagają opracować wyniki analiz. Może to być np. zapisywanie modelu lub robienie ponownej predykcji na innych danych. W przypadku Random Forest taką dodatkową metodą jest np. *feature importance*. W związku z tym jako wynik walidacji krzyżowej warto jest przekazać również utworzone  modele. Zróbmy jeszcze jedną modyfikację funkcji walidacji krzyżowej - dodajmy parametr `saveModels = False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-18T15:50:04.751933Z",
     "start_time": "2020-01-18T15:50:04.745952Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "# Przygotujmy wrapper\n",
    "def CVTestRFClass(nFolds = 5, randomState=2020, debug=False, features=features, saveModels = False, *args, **kwargs):\n",
    "    \n",
    "    # Przygotujmy walidację krzyżową\n",
    "    kf = KFold(n_splits=nFolds, shuffle=True, random_state=randomState)\n",
    "\n",
    "    # Aby oszczędzać pamięć informacja o foldach to wyłącznie numery wierszy\n",
    "    testResults = []\n",
    "    \n",
    "    # Dla kompletności dodamy informację o w ynikach na zbiorze treningowym\n",
    "    trainResults = []\n",
    "    \n",
    "    # Przechowajmy również predykcje dla poszczególnych foldów\n",
    "    predictions = []\n",
    "    # Razem z informacją o tym, jaki był ich indeks w oryginalnym zbiorze danych\n",
    "    indices = []\n",
    "    \n",
    "    # Przygotujmy liste modeli do zachowania\n",
    "    models = []\n",
    "    \n",
    "    # Pętla walidująca modele\n",
    "    for train, test in kf.split(df.index.values):\n",
    "        # Przygotowanie estymatora\n",
    "        clf = RandomForestClassifier(*args, **kwargs, random_state=randomState, n_jobs=-1)\n",
    "        if debug:\n",
    "            print(clf)\n",
    "        # Trenowanie modelu\n",
    "        clf.fit(df.iloc[train][features], df.iloc[train][target])\n",
    "\n",
    "        # Przygotowanie prognoz dla zbioru treningowego i testowego\n",
    "        # UWAGA sklearn zwracał będzie dwie kolumny prawdopodobieństw dla obydwu klas\n",
    "        predsTrain = clf.predict_proba(df.iloc[train][features])[:,1]\n",
    "        preds = clf.predict_proba(df.iloc[test][features])[:,1]\n",
    "        \n",
    "        # Zachowajmy informacje o predykcjach dla tego foldu\n",
    "        predictions.append(preds.tolist().copy())\n",
    "        \n",
    "        # Razem z indeksami w oryginalnym data frame\n",
    "        indices.append(df.iloc[test].index.tolist().copy())\n",
    "        \n",
    "        # Policzenie dopasowania metryką ROC-AUC\n",
    "        trainScore = roc_auc_score((df[target].iloc[train]==\"yes\").astype(int), predsTrain)\n",
    "        testScore = roc_auc_score((df[target].iloc[test]==\"yes\").astype(int), preds)\n",
    "        \n",
    "        # zapisanie wyników z iteracji\n",
    "        trainResults.append(trainScore)\n",
    "        testResults.append(testScore)\n",
    "        \n",
    "        # Informowanie o każdym foldzie razem z wynikami treningowymi możemy opcjonalnie wyświetlać w trakcie\n",
    "        if debug:\n",
    "            print(\"Train AUC:\", trainScore,\n",
    "                  \"Valid AUC:\", testScore)\n",
    "        \n",
    "        # Zapisanie wyników do listy models\n",
    "        if saveModels:\n",
    "            models.append(clf)\n",
    "    \n",
    "    # Lista zwracanych wyników - zwróćmy uwagę na nowy obiekt models\n",
    "    return trainResults, testResults, predictions, indices, models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wykonajmy trening modelu:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-18T15:50:10.259394Z",
     "start_time": "2020-01-18T15:50:05.121746Z"
    }
   },
   "outputs": [],
   "source": [
    "trainResults, testResults, predictions, indices, models = CVTestRFClass(n_estimators=500, max_depth=20,\n",
    "                                                                    max_features=4,\n",
    "                                                                    min_samples_split=4, min_samples_leaf=1,\n",
    "                                                                        saveModels=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dzięki zapisaniu modeli, możemy wybrać jeden z nich i zobaczyć które zmienne były najczęściej wykorzystywane w drzewach, które algorytm może uznać za najważniejsze. Zobaczmy czy wynik będzie podobny pomiędzy foldami."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-18T15:53:35.872024Z",
     "start_time": "2020-01-18T15:53:35.761531Z"
    }
   },
   "outputs": [],
   "source": [
    "imps = list(zip(models[0].feature_importances_, features))\n",
    "imps.sort(reverse=True)\n",
    "imps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-18T15:53:36.180546Z",
     "start_time": "2020-01-18T15:53:36.074360Z"
    }
   },
   "outputs": [],
   "source": [
    "imps = list(zip(models[1].feature_importances_, features))\n",
    "imps.sort(reverse=True)\n",
    "imps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jak widać uzyskujemy dosyć podobne wnioski jak w przypadku analizy z uzyciem algorytmu kNN. Duration hest zdecydowanie najważniejszą zmienną. Zmienne, age, day i balance również okazywały się być istotne w obydwu przypadkach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ćwiczenia\n",
    "* Sprawdź czy zmiana parametrów min_weight_fraction_leaf oraz min_impurity_decrease może pomóc nam poprawić nasz model.\n",
    "* Na zbiorze Boston Housing przygotuj model regresyjny z wykorzystaniem Random Forest Regressor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
